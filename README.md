# Credit Card Fraud Detection

![Fraud Detection](https://github.com/thisissophiawang/credit-card-fraud-detection/blob/main/banner.png)

## ğŸ“Œ Project Overview

This project implements advanced data mining techniques to detect fraudulent credit card transactions.

With global fraud losses exceeding **$28.65 billion annually**, we aim to tackle key challenges such as **imbalanced data, computational efficiency, and evolving fraud patterns**.

### ğŸ” Key Challenges Addressed

- **Severe Class Imbalance**: Only **0.17%** (492 out of 284,807) transactions are fraudulent
- **Computational Complexity**: **28 PCA-transformed features** requiring efficient processing
- **Evolving Fraud Patterns**: Adapting to **changing fraud tactics** over time

## ğŸ“Š Dataset

We utilized the **[Credit Card Fraud Detection Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud)** from Kaggle, which contains:

âœ” **284,807 transactions** (492 fraudulent cases)  
âœ” **28 principal components** (from PCA transformation)  
âœ” **Time elapsed features** and **transaction amounts**  
âœ” **Anonymized data** to protect user privacy

## âš™ï¸ Methodology

### 1ï¸âƒ£ Data Preprocessing

âœ… Feature scaling with **RobustScaler**  
âœ… **Correlation analysis** and feature selection  
âœ… **Class Imbalance Handling**: Implemented **SMOTE (Synthetic Minority Over-sampling Technique)**  
âœ… **Outlier Detection**: Used **Isolation Forest** to identify and handle anomalies  
âœ… **Stratified train-test splitting**

### 2ï¸âƒ£ Models Implemented

#### ğŸ”¹ Random Forest Classifier

âœ” **Configuration**: 100 trees, max depth of 10, balanced class weights  
âœ” **ROC-AUC Score**: 0.979  
âœ” **Threshold Optimization**: Improved F1 score from 0.5784 to 0.8021 (38.67% improvement)  
âœ” Feature importance analysis

#### ğŸ”¹ Neural Network

âœ” **Architecture**: Three hidden layers (64, 32, 16 neurons) with batch normalization  
âœ” **Activation**: ReLU for hidden layers, Sigmoid for output  
âœ” **Optimization**: Adam with learning rate of 0.001  
âœ” **Dropout layers** (0.3) to prevent overfitting

## ğŸ“ˆ Evaluation Metrics

- **Precision, Recall, and F1-Score**
- **ROC Curve and AUC**
- **Confusion Matrix Analysis**
- **Probability Distribution Analysis**

### ğŸš€ Results

| Model | Precision | Recall | F1-Score | AUC |
|-------|-----------|--------|----------|-----|
| Random Forest | **0.96** | 0.83 | 0.89 | 0.97 |
| Neural Network | 0.89 | **0.91** | **0.90** | 0.96 |

### ğŸ“Š Performance Insights

- **Random Forest**: Better interpretability with clearer feature importance rankings
- **Neural Network**: Superior at capturing complex fraud patterns with fewer false positives
- **Threshold Optimization**: Critical for improving model performance in imbalanced datasets

## ğŸ”¬ Key Findings

1. **Model Performance Enhancement**: Neural Network achieved high recall (0.85) and precision (0.87)
2. **SMOTE's Role**: Transformed dataset from 0.17% fraudulent transactions to a balanced distribution
3. **Comparative Insights**: Random Forest provided better interpretability while Neural Network reduced false positives

## ğŸ”® Future Improvements

- [ ] Implement **real-time fraud detection capability**
- [ ] Explore **ensemble methods** for improved performance
- [ ] Develop an **adaptive learning approach** for evolving fraud patterns
- [ ] Create a **web-based dashboard** for monitoring fraud detection metrics
- [ ] Implement **XAI techniques** (SHAP, LIME) for better model interpretability

## ğŸ’» Installation and Usage

### ğŸ“Œ Requirements

```plaintext
numpy==1.26.4
pandas==2.2.1
scikit-learn==1.4.2
tensorflow==2.15.0
matplotlib==3.8.3
seaborn==0.13.2
imbalanced-learn==0.12.0
```

### ğŸš€ Setup and Execution

```bash
# Clone the repository
git clone https://github.com/thisissophiawang/credit-card-fraud-detection.git
cd credit-card-fraud-detection

# Install dependencies
pip install -r requirements.txt

# Run the preprocessing pipeline
python src/preprocessing.py

# Train and evaluate models
python src/train_models.py
```

## ğŸ“‹ Project Structure

```
credit-card-fraud-detection/
â”œâ”€â”€ data/                          # Dataset files
â”œâ”€â”€ models/                        # Saved model files
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for exploration
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ preprocessing.py           # Data preprocessing pipeline
â”‚   â”œâ”€â”€ models.py                  # Model implementations
â”‚   â”œâ”€â”€ evaluation.py              # Model evaluation metrics
â”‚   â””â”€â”€ visualization.py           # Visualization utilities
â”œâ”€â”€ requirements.txt               # Project dependencies
â””â”€â”€ README.md                      # Project documentation
```

## ğŸ”— References

- Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5-32.
- Chawla, N. V., et al. (2002). SMOTE: Synthetic Minority Over-sampling Technique. *Journal of Artificial Intelligence Research*, 16, 321-357.
- Dal Pozzolo, A., et al. (2015). Calibrating Probability with Undersampling for Unbalanced Classification. *IEEE Symposium Series on Computational Intelligence and Data Mining*.
- FernÃ¡ndez, A., et al. (2018). Learning from Imbalanced Data Sets. *Springer*.





